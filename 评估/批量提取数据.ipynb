{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "\n",
    "# zylshs = np.loadtxt('/HL_user01/yc_ruxianwaike_test/2024_5_31出院小结完整演示_wjc版/流水号/ruxianwaike_新增源文件流水号0-100.csv', delimiter=',',dtype=str)\n",
    "# zylshs = list(zylshs)\n",
    "cyxj_format = {\n",
    "    \"患者基本信息\": {\n",
    "        \"住院号\": \"基本信息---住院号\",\n",
    "        \"床号\": \"基本信息---床号\",\n",
    "        \"入院时间\": \"基本信息---入院时间\",\n",
    "        \"出院时间\": \"基本信息---出院时间\",\n",
    "        \"科别\": \"基本信息---科别\",\n",
    "        \"科室\": \"病人信息---科室\",\n",
    "        \"姓名\": \"基本信息---姓名\",\n",
    "        \"年龄\": \"基本信息---年龄\",\n",
    "        \"性别\": \"基本信息---性别\",\n",
    "        \"脉搏(P)\": \"生命体征---P\",\n",
    "        \"呼吸(R)\": \"生命体征---R\",\n",
    "        \"体温(T)\": \"生命体征---T\",\n",
    "        \"高压(BP高)\": \"生命体征---BP高\",\n",
    "        \"低压(BP低)\": \"生命体征---BP低\",\n",
    "        \"入院诊断\": \"基本信息---入院诊断\",\n",
    "        \"入院时简要病史\": \"入院时简要病史\",\n",
    "        \"体检摘要\": \"体检摘要\"\n",
    "    },\n",
    "    \"出院诊断\": \"基本信息---出院诊断\",\n",
    "    \"住院期间医疗情况\": \"住院期间医疗情况\",\n",
    "    \"出院时情况\": \"出院时情况\",\n",
    "    \"病程与治疗情况\": \"病程与治疗情况\",\n",
    "    \"出院后用药建议\": \"出院后用药建议\",\n",
    "}\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path,'r') as f:\n",
    "        content = json.load(f)\n",
    "    return content\n",
    "\n",
    "def create_dirs(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "def get_jsonlines(zylsh_ziduans,keshi,pred_dir,gold_dir,out_dir,out_name):\n",
    "    pred_datas = []\n",
    "    zylshs = zylsh_ziduans.keys()\n",
    "    truth = read_json(f'/HL_user01/yc_ruxianwaike_test/2024_5_31出院小结完整演示_wjc版/评估/wjc_zylshs/{keshi}_truth.json')\n",
    "    for zylsh in tqdm(zylshs):\n",
    "        model_path = os.path.join(pred_dir,keshi,zylsh,f\"{zylsh}_postprocessed.json\")\n",
    "        source_path = os.path.join(pred_dir,keshi,zylsh,f\"{zylsh}_findsource.json\")\n",
    "        doctor_path = os.path.join(gold_dir,keshi,zylsh,f\"{zylsh}.json\")\n",
    "        try : \n",
    "            model_content = read_json(model_path)\n",
    "            source_content = read_json(source_path)\n",
    "            doctor_content = read_json(doctor_path)\n",
    "        except FileNotFoundError:\n",
    "            print(zylsh)\n",
    "            continue\n",
    "        \n",
    "        # 处理模型生成的格式\n",
    "        ori_datas = model_content[zylsh]\n",
    "        model_formats = deepcopy(cyxj_format)\n",
    "        for key, value in model_formats.items():\n",
    "            if isinstance(value, dict):\n",
    "                for sub_key, path in value.items():\n",
    "                    path_parts = path.split('---')\n",
    "                    data = ori_datas\n",
    "                    for part in path_parts:\n",
    "                        data = data.get(part, \"\")\n",
    "                        if isinstance(data, list):\n",
    "                            if len(data)>=1:\n",
    "                                data=data[0]\n",
    "                    model_formats[key][sub_key] = data\n",
    "            elif isinstance(value, str):\n",
    "                path_parts = value.split('---')\n",
    "                data = ori_datas\n",
    "                for part in path_parts:\n",
    "                    data = data.get(part, \"\")\n",
    "                    if isinstance(data, list):\n",
    "                        if len(data)>=1:\n",
    "                            data=data[0]\n",
    "                model_formats[key] = data\n",
    "        # print(json.dumps(model_formats,ensure_ascii = False,indent=2))\n",
    "        # 处理医生的格式\n",
    "        ori_datas = doctor_content[zylsh]\n",
    "        doctor_formats = deepcopy(cyxj_format)\n",
    "        for key, value in doctor_formats.items():\n",
    "            if isinstance(value, dict):\n",
    "                for sub_key, path in value.items():\n",
    "                    path_parts = path.split('---')\n",
    "                    data = ori_datas\n",
    "                    for part in path_parts:\n",
    "                        data = data.get(part, \"\")\n",
    "                        if isinstance(data, list):\n",
    "                            if len(data)>=1:\n",
    "                                data=data[0]\n",
    "                    doctor_formats[key][sub_key] = data\n",
    "            elif isinstance(value, str):\n",
    "                path_parts = value.split('---')\n",
    "                data = ori_datas\n",
    "                for part in path_parts:\n",
    "                    data = data.get(part, \"\")\n",
    "                    if isinstance(data, list):\n",
    "                        if len(data)>=1:\n",
    "                            data=data[0]\n",
    "                doctor_formats[key] = data\n",
    "\n",
    "        # 采用真truth\n",
    "        truth_formats = truth[zylsh]\n",
    "        if '患者基本信息' in zylsh_ziduans[zylsh]:\n",
    "            truth_formats['患者基本信息'] = json.loads(truth_formats['患者基本信息'])\n",
    "            truth_formats['患者基本信息']['住院号'] = doctor_formats['患者基本信息']['住院号']\n",
    "            truth_formats['患者基本信息']['床号'] = doctor_formats['患者基本信息']['床号']\n",
    "            truth_formats['患者基本信息']['姓名'] = doctor_formats['患者基本信息']['姓名']\n",
    "        # print(json.dumps(doctor_formats,ensure_ascii = False,indent=2))\n",
    "\n",
    "        for key in cyxj_format.keys():\n",
    "            # 判断是否评分中的数据\n",
    "            if key not in zylsh_ziduans[zylsh]:\n",
    "                continue\n",
    "            temp_dict = {}\n",
    "            if key == '患者基本信息':\n",
    "                model_formats[key] = json.dumps(model_formats[key],ensure_ascii = False)\n",
    "                truth_formats[key] = json.dumps(truth_formats[key],ensure_ascii = False)\n",
    "            temp_dict['pred'] = model_formats[key]\n",
    "            temp_dict['output'] = truth_formats[key]\n",
    "            temp_dict['instruction'] = source_content[zylsh][key]\n",
    "            temp_dict['key'] = key\n",
    "            temp_dict['zylsh'] = zylsh\n",
    "            pred_datas.append(temp_dict)\n",
    "\n",
    "    create_dirs(out_dir)\n",
    "    with jsonlines.open(os.path.join(out_dir,out_name),'w') as f:\n",
    "        for pred_data in pred_datas:\n",
    "            f.write(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:00<00:00, 585.15it/s]\n"
     ]
    }
   ],
   "source": [
    "keshi = 'ruxianwaike'\n",
    "pred_dir = '/HL_user01/yc_ruxianwaike_test/2024_5_31出院小结完整演示_wjc版/model_generated_test'\n",
    "gold_dir = '/HL_user01/yc_ruxianwaike_test/2024_5_31出院小结完整演示_wjc版/doctor_generated'\n",
    "# zylshs = os.listdir(os.path.join(pred_dir,keshi))\n",
    "# zylshs = np.loadtxt('/HL_user01/yc_ruxianwaike_test/2024_5_31出院小结完整演示_wjc版/流水号/ruxianwaike_新增源文件流水号_747.csv', delimiter=',',dtype=str)\n",
    "# zylshs = list(zylshs)\n",
    "zylsh_ziduans = read_json('/HL_user01/yc_ruxianwaike_test/2024_5_31出院小结完整演示_wjc版/评估/wjc_zylshs/ruxianwaike.json')\n",
    "out_dir = os.path.join('2_emr_6/',keshi,'出院小结及子字段_test')\n",
    "out_name = 'preds.json'\n",
    "get_jsonlines(zylsh_ziduans,keshi,pred_dir,gold_dir,out_dir,out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(save_path,content):\n",
    "    with open(save_path,'w',encoding='utf8') as f:\n",
    "        json.dump(content,f,ensure_ascii=False,indent=2)\n",
    "\n",
    "def get_wjc_zylsh(keshi,out_dir,out_name):\n",
    "    zylshs = {}\n",
    "    output_zylsh_ziduans = {}\n",
    "    pred_path = os.path.join(out_dir,out_name)\n",
    "    with jsonlines.open(pred_path,'r') as f:\n",
    "        for data in f:\n",
    "            if 'output' not in data.keys():\n",
    "                break\n",
    "            # print(data['zylsh'])\n",
    "            if data['zylsh'] not in zylshs.keys():\n",
    "                zylshs[data['zylsh']] = []\n",
    "                output_zylsh_ziduans[data['zylsh']] = {}\n",
    "            zylshs[data['zylsh']].append(data['key'])\n",
    "            output_zylsh_ziduans[data['zylsh']][data['key']] = data['output']\n",
    "    a = np.array(list(zylshs.keys()))\n",
    "    create_dirs('wjc_zylshs')\n",
    "    save_json(f'./wjc_zylshs/{keshi}.json',zylshs)\n",
    "    save_json(f'./wjc_zylshs/{keshi}_truth.json',output_zylsh_ziduans)\n",
    "    np.savetxt(f'./wjc_zylshs/{keshi}.csv', a, fmt=\"%s\", delimiter=',')\n",
    "\n",
    "\n",
    "keshi = 'ruxianwaike'\n",
    "out_dir = os.path.join('/HL_user01/0726_wjc_upload/每个科室单独的指标/2_emr_6',keshi,'出院小结及子字段_test')\n",
    "out_name = 'preds.json'\n",
    "get_wjc_zylsh(keshi,out_dir,out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_our_zylsh(keshi,out_dir,out_name):\n",
    "    zylshs = {}\n",
    "    pred_path = os.path.join(out_dir,out_name)\n",
    "    with jsonlines.open(pred_path,'r') as f:\n",
    "        for data in f:\n",
    "            if 'output' not in data.keys():\n",
    "                break\n",
    "            # print(data['zylsh'])\n",
    "            if data['zylsh'] not in zylshs.keys():\n",
    "                zylshs[data['zylsh']] = []\n",
    "            zylshs[data['zylsh']].append(data['key'])\n",
    "    a = np.array(list(zylshs.keys()))\n",
    "    create_dirs('our_zylshs')\n",
    "    save_json(f'./our_zylshs/{keshi}.json',zylshs)\n",
    "    np.savetxt(f'./our_zylshs/{keshi}.csv', a, fmt=\"%s\", delimiter=',')\n",
    "\n",
    "\n",
    "keshi = 'ruxianwaike'\n",
    "out_dir = os.path.join('./2_emr_6',keshi,'出院小结及子字段_test')\n",
    "out_name = 'preds.json'\n",
    "get_our_zylsh(keshi,out_dir,out_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
