{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from decimal import Decimal\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "#cuda_DEVICE = ['cuda:3','cuda:4']\n",
    "\n",
    "def load_model(which_model):\n",
    "    if which_model == 'model1': # 原始模型\n",
    "        model_path = '/HL_user01/llm_models/chatglm3-6b'\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        model = AutoModel.from_pretrained(model_path, trust_remote_code=True,device='cuda:1')\n",
    "    elif which_model == 'model_wjc': # 全科室模型\n",
    "        model_path = '/HL_user01/trained_models/0229_ck36000_sft_stage4_lora_03-27-09-27-27_export_model'\n",
    "        # model_path = '/data/wangjiacheng/瑞金/1228_测试/export_models/chuyuanxiaojie_1201'\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        model = AutoModel.from_pretrained(model_path,torch_dtype=torch.float16, trust_remote_code=True,device='cuda:1')\n",
    "    elif which_model == 'model_ht': # 华佗\n",
    "        model_path = '/HL_user01/medical_llm/HuatuoGPT2-7b'\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        model = AutoModel.from_pretrained(model_path,torch_dtype=torch.float16, trust_remote_code=True)\n",
    "        \n",
    "    model = model.eval()\n",
    "    return model,tokenizer\n",
    "\n",
    "#model_path = '/HL_user01/llm_models/chatglm3-6b'\n",
    "#model_path = '/HL_user01/lyh/trained_model/all_cyxjs_chatglm3_lora_lyh627/checkpoint-2000'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code=True)\n",
    "# model = AutoModel.from_pretrained(model_path,trust_remote_code=True).cuda()\n",
    "# model = model.eval()\n",
    "\n",
    "which_model='model_wjc'\n",
    "model,tokenizer=load_model(which_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-03-19 12:20:29\\n描述:心电图|常规心电图|心电图|\\n图像分析:窦性心律不齐\\n\\n', '2019-03-19 14:27:08\\n描述:放射|胸部|X-ray平片|胸部 胸部\\n图像所见:所示胸廓骨骼及胸壁软组织未见异常。 纵隔及气管居中未见移位。 纵隔未见增宽。 心脏形态大小未见异常。 两膈光整，两肋膈角锐利。 肺门形态大小位置未见异常。 两肺纹理略增多。\\n图像分析:两肺纹理略多。请结合临床及其他相关检查。\\n']\n",
      "窦性心律不齐\n",
      "是\n",
      "心内科\n",
      "两肺纹理略多。\n",
      "是\n",
      "呼吸科\n",
      "患者心电图：窦性心律不齐，建议于心内科随访。患者X-ray平片：两肺纹理略多，建议于呼吸科随访。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "jiancha_source='''\n",
    "##日常病程记录\n",
    "时间:2019-03-19\n",
    "文本:患者今日超声引导下行右侧腋窝及锁骨上淋巴结细针穿刺术。 影像描述:A:于右侧腋窝可见几个低回声，之一大小约 24.7×9.3mm。淋巴结间未见相互融合，包膜光整，与周围软组织分界清，外形呈椭圆形，淋巴结淋巴门偏心移位，淋巴结内部呈低回声(与毗邻肌肉相比较)，分布较均，未见明显钙化强回声，未见明显液化无回声。CFI可显示淋巴结淋巴门血管，较丰富。 B:于右侧锁骨上可见几个低回声，之一大小约7.2×5.0 mm。淋巴结间未见相互融合，包膜光整，与周围软组织分界清，外形趋圆，淋巴结淋巴门不明显，淋巴结内部呈低回声(与毗邻肌肉相比较)，分布较均，未见明显钙化强回声，未见明显液化无回声。CFI可显示淋巴结淋巴门血管，较丰富。 穿刺记录:取仰卧位，充分暴露锁骨上，常规消毒，予7#穿刺细针，超声引导下穿刺，抽吸标本满意，涂片2张。穿刺点局部压迫后无出血。术后注意穿刺点情况。如有出血、穿刺点肿胀等严重者及时通知床位医生或护士。 诊断意见:A:右侧腋窝淋巴结穿刺2次，待细胞学结果B:右侧锁骨上淋巴结穿刺2次，待细胞学结果。\n",
    "\n",
    "###异常检验指标\n",
    "报告时间:2019-03-19 11:54:04\n",
    "检验详情:INR:0.91,未判断;\n",
    "\n",
    "报告时间:2019-03-19 12:48:52\n",
    "检验详情:估算肾小球滤过率:121.2ml/min/1.73m2,未判断;\n",
    "\n",
    "报告时间:2019-03-20 08:34:42\n",
    "检验详情:乙肝病毒核心抗体:8.74(+),偏高; 乙肝病毒表面抗体:494.06(+)mIU/mL,偏高; 乙肝病毒e抗体:0.01(+),偏低;\n",
    "\n",
    "报告时间:2019-03-20 14:50:56\n",
    "检验详情:丙肝病毒抗体(HCV-Ab):阴性(-),未判断; 艾滋病毒抗体(HIV):阴性(-),未判断;\n",
    "\n",
    "###全部检查\n",
    "报告时间:2019-03-19 12:20:29\n",
    "描述:心电图|常规心电图|心电图|\n",
    "图像分析:窦性心律不齐\n",
    "\n",
    "报告时间:2019-03-19 14:27:08\n",
    "描述:放射|胸部|X-ray平片|胸部 胸部\n",
    "图像所见:所示胸廓骨骼及胸壁软组织未见异常。 纵隔及气管居中未见移位。 纵隔未见增宽。 心脏形态大小未见异常。 两膈光整，两肋膈角锐利。 肺门形态大小位置未见异常。 两肺纹理略增多。\n",
    "图像分析:两肺纹理略多。请结合临床及其他相关检查。\n",
    "\n",
    "###最后一个在院评估单\n",
    "###在院评估单:\n",
    "时间:2019-03-19\n",
    "基础评估:1.生活自理能力评估: Barthel指数总分60分。2.活动能力评估: 步态因卧床无法评估 ；活动状态:卧床 ，能自行翻身 ，移动患者时，摩擦力和剪切力无明显问题（可独立在床上或椅子上移动，移动时有足够的肌力将身体抬高，坐在椅子或床上随时都可以维持良好的体位） 。 3.意识状况评估:神志: 清醒 ，感知觉未受损（对指令有反应，能准确表达疼痛和不适） 。 4.粘膜与皮肤状况评估:颜色: 正常 ；温度: 正常 ；湿度: 正常（皮肤经常保持干燥，只需常规更换床单） ；皮肤完整性: 不完整 ，皮肤不完整原因切口 ，切口部位 胸部 。 无 水肿 ；无 静脉炎 ；无 瘙痒；无 麻木；无 灼烧感 。5.疼痛: 有 疼痛，切口疼痛，呈间隙性疼痛，轻度（注意时，有觉察） ，疼痛评分1分 。 6.排泄: 无 失禁 。 7.意外事件评估: 未发生意外事件。 营养状况评估:良好(饮食摄入和平时一样，每餐有蛋白质摄入) ，无营养支持。 危重症程度评估: 无 严重器官系统功能不全。 \n",
    "\n",
    "      \n",
    "'''\n",
    "all_jiancha=jiancha_source[jiancha_source.find('###全部检查')+8:jiancha_source.find('###最后一个在院评估单')]\n",
    "all_jiancha=all_jiancha[:all_jiancha.find('###')]\n",
    "jiancha_list=re.split(r'报告时间:',all_jiancha)\n",
    "jiancha_list=list(filter(None,jiancha_list))\n",
    "print(jiancha_list)\n",
    "\n",
    "suifang_dic={}\n",
    "suifang_suggestion=''\n",
    "\n",
    "for item in jiancha_list:\n",
    "    item = item[item.find('描述'):]\n",
    "    flag, history = model.chat(tokenizer, \"请根据检查结果中的‘图像分析’，判断下面的检查结果是否需要随访，请从['是'，'否']中选择一个输出，不要输出其他内容。\\n \"+item, history=[] ,temperature=0.01)\n",
    "    \n",
    "    desc_match = re.search(r'描述:(.*?)(?:\\n|$)', item)\n",
    "    if desc_match:\n",
    "        description = desc_match.group(1).split('|')[-2]+'：'\n",
    "        # description = description[:description.find(' ')]+'：'\n",
    "    else:\n",
    "        description = ''\n",
    "    # print(description)\n",
    "    jiancha_summary,history= model.chat(tokenizer,\"你是一位专业医生，请将下面的检查进行总结，请直接输出总结出的图像异常的检查项目和检查结果，精炼语句，将输出控制在一句话，不要提出建议\\n\"+item, history=[] ,temperature=0.01)\n",
    "    jiancha_summary = jiancha_summary.replace(\"，随诊\",\"\").replace(\"，随访\",\"\")\n",
    "    print(jiancha_summary)\n",
    "    jiancha_summary=description+ jiancha_summary\n",
    "    flag, history = model.chat(tokenizer, \"请判断下面的检查结果是否有异常，有异常输出‘是’,没有异常输出‘否’,请从['是'，'否']中选择一个输出，不要输出其他内容。\\n \"+ jiancha_summary, history=[] ,temperature=0.01)\n",
    "    if '其他检查' in item or '，随诊' in item or'，随访' in item or '其他相关检查' in item :\n",
    "        flag='是'\n",
    "    if '明显异常' in jiancha_summary or '未见异常' in jiancha_summary or '未发现异常' in jiancha_summary:\n",
    "        flag='否'\n",
    "    print(flag)\n",
    "    \n",
    "\n",
    "    if '是' in flag or flag=='需要随访。':\n",
    "        rjkeshi_list=\"，请从下面的科室列表中选择随访科室:[‘心内科’,‘呼吸科’,‘乳腺外科’,‘胰腺外科’,‘消化科’,‘高血压科’,‘骨科’,‘妇科’,‘血液科’,‘耳鼻喉科’,‘甲状腺血管科’,‘神经内科’,‘神经外科’,‘肾脏内科’,‘内分泌科’,‘胃肠外科’,‘小儿科’]\"\n",
    "        suifang_keshi,history= model.chat(tokenizer,\"你是一位专业医生，请根据下面的检查给出对应的随访科室\"+rjkeshi_list+\"，请最后输出唯一随访科室名称，例如：某某科，不要输出其他内容。\\n\"+item, history=[] ,temperature=0.01)\n",
    "        print(suifang_keshi)\n",
    "        if(suifang_dic.get(suifang_keshi,0)):\n",
    "            suifang_dic[suifang_keshi]+=jiancha_summary\n",
    "        else:\n",
    "            suifang_dic[suifang_keshi]=jiancha_summary\n",
    "        # jiancha_summary=jiancha_summary[:-1]\n",
    "        # suifang_keshi='，建议于'+suifang_keshi+'随访。'\n",
    "        # print(\"患者\"+jiancha_summary+suifang_keshi)\n",
    "\n",
    "for i in suifang_dic:\n",
    "    jiancha_suggestion=suifang_dic[i]\n",
    "    if jiancha_suggestion[-1]=='。':\n",
    "        jiancha_suggestion=jiancha_suggestion[:-1]\n",
    "    keshi_suggestion='，建议于'+i+'随访。'\n",
    "    suifang_suggestion = '{}{}'.format(suifang_suggestion, \"患者\"+jiancha_suggestion+keshi_suggestion)\n",
    "\n",
    "\n",
    "print(suifang_suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案', '患者窦性心动过缓，I°房室传导阻滞，建议于心血管内科随访。患者两肺纹理略多，左下肺小结节影，主动脉迂曲钙化，建议于呼吸科随访', '10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案', '术后胸带加压包扎切口5天；之后可佩戴文胸；保持伤口清洁干燥，2周内避免洗澡；术后10天内每3天来院换药一次，换药门诊时间：每周一～周五9:00-11:00 在门诊大楼3楼乳腺中心', '保持伤口清洁干燥，如有发热，切口局部红肿、疼痛、化脓等不适，及时来院就诊。\\n']\n",
      "1.10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案。\n",
      "2.10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案。\n",
      "3.术后胸带加压包扎切口5天；之后可佩戴文胸；保持伤口清洁干燥，2周内避免洗澡；术后10天内每3天来院换药一次，换药门诊时间：每周一～周五9:00-11:00 在门诊大楼3楼乳腺中心。\n",
      "4.保持伤口清洁干燥，如有发热，切口局部红肿、疼痛、化脓等不适，及时来院就诊。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_kesuifang(item):\n",
    "    return \"科随访\" not in item\n",
    "\n",
    "suggestion='''1.10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案。\\n1.患者窦性心动过缓，I°房室传导阻滞，建议于心血管内科随访。患者两肺纹理略多，左下肺小结节影，主动脉迂曲钙化，建议于呼吸科随访。\n",
    "2.10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案。\n",
    "2.术后胸带加压包扎切口5天；之后可佩戴文胸；保持伤口清洁干燥，2周内避免洗澡；术后10天内每3天来院换药一次，换药门诊时间：每周一～周五9:00-11:00 在门诊大楼3楼乳腺中心。\n",
    "3.保持伤口清洁干燥，如有发热，切口局部红肿、疼痛、化脓等不适，及时来院就诊。\n",
    "'''\n",
    "\n",
    "\n",
    "pattern = r'[。|;][\\n|''|' ']\\d.' \n",
    "# suggestion,historty=model.chat(tokenizer,test_input, history=[] ,temperature=0.01)\n",
    "\n",
    "suggestion_list=re.split(pattern,suggestion)\n",
    "print(suggestion_list)\n",
    "suggestion_list = list(filter(filter_kesuifang, suggestion_list))\n",
    "\n",
    "final_suggestion=''\n",
    "if re.match(r'\\d\\.',suggestion_list[0][:2]):\n",
    "    suggestion_list[0]=suggestion_list[0][2:]\n",
    "num=1\n",
    "\n",
    "for s in suggestion_list:\n",
    "    if num < len(suggestion_list):\n",
    "        final_suggestion+=str(num)+'.'+s+'。\\n'\n",
    "    else:\n",
    "        final_suggestion+=str(num)+'.'+s\n",
    "    num+=1\n",
    "\n",
    "\n",
    "print(final_suggestion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乳腺外科\n",
      "乳腺增强MRI：左乳头后方肿块伴坏死可能，炎症待排，建议穿刺活检。双乳腺病伴多发腺病结节，BI-RADS 3类。\n",
      "患者乳腺增强MRI：左乳头后方肿块伴坏死可能，炎症待排，建议穿刺活检。双乳腺病伴多发腺病结节，BI-RADS 3类，建议于乳腺外科随访。\n"
     ]
    }
   ],
   "source": [
    "if '是'in flag:\n",
    "    suifang_keshi,history= model.chat(tokenizer,\"你是一位专业医生，请根据下面的检查给出对应的随访科室，请直接输出建议随访科室。请从下面的科室列表中选择随访科室:[‘呼吸科’,‘乳腺外科’,‘胰腺外科’,‘消化科’,‘高血压科’,‘骨科’,‘心内科’,‘妇科’,‘血液科’,‘肝胆外科’]\\n\"+jiancha, history=[] ,temperature=0.01)\n",
    "    print(suifang_keshi)\n",
    "    jiancha_summary,history= model.chat(tokenizer,\"你是一位专业医生，请将下面的检查进行总结，请直接输出总结出的图像检查结果，不要提出建议\\n\"+jiancha, history=[] ,temperature=0.01)\n",
    "    print(jiancha_summary)\n",
    "    jiancha_summary=jiancha_summary[:-1]\n",
    "    suifang_keshi='，建议于'+suifang_keshi+'随访。'\n",
    "\n",
    "print(\"患者\"+jiancha_summary+suifang_keshi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "呼吸科\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def input_all_jiancha(ICL,promote, question):\n",
    "    return \"{}\\n{}\\n\\n检查结果:\\n{}\\n\\n随访科室:\".format(ICL,promote, question)\n",
    "\n",
    "def compose_zs_prompt_jiancha(question,context):\n",
    "    return \"检查结果:\\n{}\\n\\n随访建议：\\n{}\\n\".format(question, context)\n",
    "\n",
    "#例子\n",
    "text1 = '''心电图提示：T波轻度改变'''\n",
    "\n",
    "answer1 = '''患者心电图提示：T波轻度改变，建议于心内科随访。'''\n",
    "\n",
    "text2 = '''胸部CT检查两肺多发小结节，左肺舌段索条'''\n",
    "\n",
    "answer2 = '''患者胸部CT检查两肺多发小结节，左肺舌段索条，建议于呼吸科随访。'''\n",
    "\n",
    "text3 = '''腹部超声提示：胆囊隆起样病变（考虑胆囊息肉）'''\n",
    "\n",
    "answer3 = '''患者腹部超声提示：胆囊隆起样病变（考虑胆囊息肉），建议于肝胆外科随访。'''\n",
    "\n",
    "promote = '''你是一位专业医生，请根据检查结果，参考上面例子，从科室列表中选择随访科室:[\"呼吸科\",\"胰腺外科\",\"消化科\",\"高血压科\",\"骨科\",\"心内科\",\"妇科\",\"血液科\",\"肝胆外科\"]''' # ,并且通过自己的语言精简的描述小事件\n",
    "\n",
    "ICL = compose_zs_prompt_jiancha(text1, answer1) + '\\n' + compose_zs_prompt_jiancha(text2, answer2)+ '\\n' + compose_zs_prompt_jiancha(text3, answer3)\n",
    "\n",
    "\n",
    "\n",
    "prompt='''你是一位专业医生，参考上面的例子,请判断下面的患者的检查结果是否存在异常症状，如果有异常请给出科室随访建议(直接给出建议随访的科室)'''\n",
    "\n",
    "jiancha= \"###全部检查:\\n报告时间:2019-01-03 12:49:45\\n描述:放射|胸部|X-ray平片|胸部 胸部\\n图像分析:两肺未见明显异常。请结合临床、病史及其他检查，随访。\"\n",
    "\n",
    "input=input_all_jiancha(ICL,prompt, jiancha)\n",
    "\n",
    "response,history = model.chat(tokenizer,input, history=[] ,temperature=0.2)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1、注意休息，避免劳累，饮食以软食为主，忌辛辣刺激食物，忌烟酒。 2、出院后定期复查血常规、肝肾功能、电解质、肿瘤指标等。 3、如有腹痛、发热、便血、黑便等不适，及时就诊。 4、出院带药：杜密克（200ml*2瓶），口服，每日2次，每次20ml。 5、出院后1月左右至我院门诊随访，根据病理结果制定下一步诊疗计划。\n"
     ]
    }
   ],
   "source": [
    "test_input=\"###科室类别:\\n胃肠外科\\n\\n###全部诊断:\\n诊断时间:2023-01-07\\n诊断类型:入院诊断\\n诊断名称:直肠占位性病变\\n\\n诊断时间:2023-01-07\\n诊断类型:入院诊断(补充)\\n诊断名称:高血压病1级（高危）\\n\\n诊断时间:2023-01-09\\n诊断类型:出院诊断\\n诊断名称:直肠占位性病变\\n\\n诊断时间:2023-01-09\\n诊断类型:出院诊断(补充)\\n诊断名称:高血压病1级（高危）\\n\\n###入院记录:\\n时间:2023-01-07\\n主治医师48小时诊断:1、直肠占位性病变 2、高血压病1级（高危） 本人对于患者基本信息及现病史内容确认无误。 患者(委托人)手写:_____ 患者(委托人)签名:_____ 与患者关系:_____ 更正/补充诊断: 更正/补充日期: 医生签名:\\n\\n###主治医师首次查房记录:\\n时间:2023-01-08\\n诊断:1、直肠占位性病变 2、高血压病1级（高危）\\n\\n###主任医师首次查房记录:\\n时间:2023-01-09\\n补充病史与体征:神清，精神一般，无 皮疹及出血点，无 全身皮肤粘膜黄染，无 浅表淋巴结肿大，无 Virchow’sLN，无 脐周质硬结节。心率60 次/分，心律齐 ，无 闻及病理性杂音。腹平坦 ，全腹软 ，全腹无 压痛，无 反跳痛，无 腹部包块，无 肝脾肋下扪及，无 移动性浊音，Murphy's征（- ），肠鸣音正常 。无 双下肢水肿。NS（-）。 肛门指检:肛管直肠表面光滑，可及肿物\\n对病情的分析:患者直肠指检于距肛门3-4cm触及肿物 。长期便秘，拟完善相关检查，判断肿物性质。\\n诊疗意见:完善相关检查，根据结果制定诊疗方案，明日出院\\n\\n###出院带药:\\n医嘱时间:2023-01-10\\n医嘱类型名称:临时医嘱\\t医嘱项名称:[出]杜密克(乳果糖口服溶液)[总:2瓶]\\t医嘱项规格:200ml/瓶\\t单次剂量数量:400.0\\t单次给药数量:2.0\\t给药途径:遵医嘱\\t给药频次:ONCE\\n\\n医嘱时间:2023-01-10\\n医嘱类型名称:临时医嘱\\t医嘱项名称:[出]皿治林(咪唑斯汀缓释片)[总:2盒]\\t医嘱项规格:10mg*7片/盒\\t单次剂量数量:10.0\\t单次给药数量:1.0\\t给药途径:口服\\t给药频次:ONCE\\n\\n###异常检验指标:\\n报告时间:2023-01-07 18:10:58\\n检验详情:新冠病毒ORF1ab基因:阴性(Neg),未判断;\\t新冠病毒N基因:阴性(Neg),未判断;\\t新型冠状病毒核酸检测:阴性(Neg),未判断;\\n\\n报告时间:2023-01-08 08:02:04\\n检验详情:淋巴细胞%:18.6％,偏低;\\t红细胞分布宽度:14.5％,偏高;\\t血红蛋白:118g/L,偏低;\\t红细胞比容:0.364,偏低;\\t仪器名称:BC-6800_3,未判断;\\t标本审核建议:Auto Validation OK,未判断;\\n\\n报告时间:2023-01-08 08:05:11\\n检验详情:Fg:3.6g/L,偏高;\\tINR:1.09,未判断;\\n\\n报告时间:2023-01-08 09:41:43\\n检验详情:上皮细胞(镜检):0/HP,未判断;\\t结晶(镜检):阴性(-),未判断;\\t红细胞(镜检):0/HP,未判断;\\t白细胞(镜检):0/HP,未判断;\\n\\n报告时间:2023-01-08 11:40:34\\n检验详情:钙:1.99mmol/L,偏低;\\t白球比例:1.19,偏低;\\t白蛋白:32g/L,偏低;\\t丙氨酸氨基转移酶:6IU/L,偏低;\\t前白蛋白:162mg/L,偏低;\\t胱抑素C:1.28mg/L,偏高;\\t估算肾小球滤过率:56.2ml/min/1.73m2,未判断;\\t钾:3.22mmol/L,偏低;\\t总蛋白:59g/L,偏低;\\n\\n报告时间:2023-01-08 18:36:15\\n检验详情:新冠病毒ORF1ab基因:阴性(Neg),未判断;\\t新冠病毒N基因:阴性(Neg),未判断;\\t新型冠状病毒核酸检测:阴性(Neg),未判断;\\n\\n报告时间:2023-01-09 11:20:56\\n检验详情:新冠病毒ORF1ab基因:阴性(Neg),未判断;\\t新冠病毒N基因:阴性(Neg),未判断;\\t新型冠状病毒核酸检测:阴性(Neg),未判断;\\n\\n报告时间:2023-01-09 12:15:55\\n检验详情:艾滋病毒抗体(HIV):阴性(-),未判断;\\t丙肝病毒抗体(HCV-Ab):0.03(-),未判断;\\n\\n报告时间:2023-01-09 13:45:14\\n检验详情:乙肝病毒e抗体:0.16(+),偏低;\\t乙肝病毒表面抗体:295.10(+)mIU/mL,偏高;\\t乙肝病毒核心抗体:6.52(+),偏高;\\n\\n报告时间:2023-01-09 14:40:36\\n检验详情:丁型肝炎病毒抗原:阴性(-),未判断;\\t丁型肝炎病毒抗体IgG:阴性(-),未判断;\\t戊型肝炎病毒抗体IgG:阴性(-),未判断;\\t戊型肝炎病毒抗体IgM:阴性(-),未判断;\\n\\n报告时间:2023-01-10 09:46:40\\n检验详情:绿链及干燥奈瑟氏菌:,偏高;\\n\\n###全部检查:\\n检查ID:2023010930000009|1\\n报告时间:2023-01-09 13:56:27\\n描述:内窥镜|电子肠镜|住院电子肠镜|电子肠镜 电子肠镜\\n图像所见:备 注：进镜至回盲部，肠道准备结肠，肠腔内多处粪渣粪水影响视野。 回盲部：见唇形回盲瓣。 升结肠：未见明显异常。 肝 曲：外来紫色压迹可见。 横结肠：结构正常，血管网纹理清晰。 脾 曲：未见明显异常。 降结肠：未见明显异常。 乙结肠：未见明显异常。 直 肠：距肛3cm左右见菜花状病灶，占肠腔3/4周。质脆易出血，活检数枚。 肛 管：未见明显异常。\\n图像分析:直肠占位\\n\\n检查ID:2023010700000930|3\\n报告时间:2023-01-10 10:33:37\\n描述:放射|增强|住院CT|胸部+上中腹部+下腹盆腔 增强\\n图像所见:直肠肠壁黏膜异常增厚强化，肠腔狭窄，周围脂肪间隙模糊伴小结节影，多发小静脉影。乙状结肠系膜、肠系膜下静脉走行区淋巴结增大。 盆腔未见阳性结石影，未见异常钙化影。 膀胱充盈差，未见异常密度。 前列腺稍大，密度未见明显异常。 腹膜后小淋巴结影。\\n图像分析:拟直肠MT，周围脂肪间隙模糊伴小结节影，周围静脉曲张，乙状结肠系膜、肠系膜下静脉走行区淋巴结增大。前列腺稍大。腹膜后小淋巴结影。请结合临床及其他检查，随诊。\\n\\n检查ID:2023010700000930|2\\n报告时间:2023-01-10 10:33:37\\n描述:放射|增强|住院CT|胸部+上中腹部+下腹盆腔 增强\\n图像所见:肝脏形态大小正常，肝内多发无强化囊性低密度影。 胆囊未见明显异常。 脾脏形态大小正常，未见异常密度影。 胰腺形态大小正常，胰头密度减低。 两肾未见异常。 腹膜后小淋巴结影。 阑尾略粗，腔内高密度影。\\n图像分析:肝多发囊肿。胰头脂肪浸润改变。阑尾略粗，粪石形成。腹膜后小淋巴结影。请结合临床及其他相关检查，随诊。\\n\\n检查ID:2023010700000930|1\\n报告时间:2023-01-10 10:33:37\\n描述:放射|增强|住院CT|胸部+上中腹部+下腹盆腔 增强\\n图像所见:左肺下叶外基底段（SE402，IM36）见一枚磨玻璃结节，长径约4mm。 左肺上叶尖后段（SE402，IM20）见一枚实性结节，长径约4mm。 右肺上叶尖段（SE402，IM18）见一枚实性结节，长径约3mm。 右肺下叶前基底段（SE402，IM38）见一枚实性结节，长径约3mm。 两肺尖胸膜稍厚。 两肺门区未见异常密度影。 主动脉，肺动脉主干及其左右分支内造影剂密度均匀。各大血管边界清晰。 纵隔内淋巴结影显示。\\n图像分析:两肺微小结节。两肺尖胸膜稍厚。纵隔内淋巴结影显示。请结合临床及其他相关检查，随诊。\\n\\n检查ID:2023010910003751|1\\n报告时间:2023-01-10 12:57:08\\n描述:放射|增强|住院MRI|直肠-MR 增强\\n图像所见:肿块特点：以稍低信号为主的混杂信号，增强轻中度强化； 肿块位置：位于直肠中下段，肿瘤最下端距离肛缘约4.2cm，位于腹膜反折以下； 肿块大小：约累及肠管长约5.1cm；约累及1周； T：肿瘤浸润至肌层外脂肪组织； N：直肠系膜内见数枚淋巴结显示，其中约3枚边界欠清，信号欠均，较大者截面大小约0.5*0.4cm；右侧侧方2枚淋巴结显示；双侧腹股沟未见明显肿大淋巴结影； MRF：受侵，为肿瘤直接侵犯； EMVI：2分。 附见：前列腺肿大，局部凸向膀胱；膀胱壁增厚；前列腺信号减低欠均，左侧团块状低信号影，弥散受限，ADC减低，增强轻度不均匀强化。\\n图像分析:直肠中下段占位，浸润至肌层外脂肪组织，拟直肠癌（mrT3aN1）病变肠段局部与前列腺外围带关系密切；MRF（+）；EMVI（-）；右侧侧方2枚淋巴结显示；双侧腹股沟未见明显肿大淋巴结影；请结合临床病史及肠镜检查。附见：前列腺肿大，信号减低欠均；膀胱充盈欠佳。\\n\\n检查ID:2023010910003841|1\\n报告时间:2023-01-10 13:00:18\\n描述:放射|平扫|住院MRI|直肠-MR 平扫\\n图像所见:距肛缘约4.2cm直肠中下段约5.1cm肠段近肠壁1周不规则增厚，肠壁欠光整，跨腹膜反折生长，病灶T2W呈稍低信号，信号欠均，DWI明显受限，ADC信号减低；浸润至固有肌层外脂肪组织可能，肠系膜内见数枚淋巴结显示，部分边界不清，信号欠均匀；右侧侧方2枚淋巴结显示；双侧腹股沟未见明显肿大淋巴结影；余所示骨盆骨质信号未见明显异常。周围软组织未见明显异常信号影。附见：前列腺肿大，局部凸向膀胱；膀胱壁增厚；前列腺信号减低欠均，左侧团块状低信号影，弥散受限，ADC减低。\\n图像分析:直肠中下段占位，浸润至固有肌层外脂肪组织可能，系膜内多枚淋巴结显示，部分边界欠清，信号不均；右侧侧方2枚淋巴结显示；请结合临床病史及相关检查，随访。附见：前列腺肿大，局部凸向膀胱；膀胱壁增厚；前列腺信号减低欠均伴左侧团块状低信号影。\\n\\n###未出检查结果报告:\\n无\\n\\n###未出结果病理报告:\\n\\n\\n检查时间:2023-01-10\\n临床诊断:直肠占位性病变\\n病理类型:常规\\n\\n###最后一个在院评估单:\\n###在院评估单:\\n时间:2023-01-10\\n基础评估:1.生活自理能力评估: Barthel指数总分100分。 。2.活动能力评估: 步态稳定 ；活动状态:活动自如 。 3.意识状况评估:神志: 清醒 ，感知觉未受损（对指令有反应，能准确表达疼痛和不适） 。 4.粘膜与皮肤状况评估:颜色: 正常 ；温度: 正常 ；湿度: 正常（皮肤经常保持干燥，只需常规更换床单） ；皮肤完整性: 完整 。 无 水肿 ；无 静脉炎 ；无 瘙痒；无 麻木；无 灼烧感 。5.疼痛: 无 疼痛 。 6.排泄: 无 失禁 。 7.意外事件评估: 未发生意外事件。 患者昨夜睡眠: 正常 营养状况评估:良好(饮食摄入和平时一样，每餐有蛋白质摄入) ，无营养支持。 危重症程度评估: 无 严重器官系统功能不全。 无 免疫损害。 格拉斯评分: 15分 。 危重症评分: 5分 。 高危因素的筛查 该病人目前不存在跌倒风险 该病人目前不存在压疮风险。 分级护理级别: 该病人分级护理建议为三级护理。\\n置管状态:无置管。 【医学元素\\\\签名\\\\护士签名2-护理评估】 【医学元素\\\\签名\\\\护士签名3-护理评估】\\n请参照患者的医疗资料，编写其出院小结文书的“出院后用药建议”字段部分。请按标准的文本格式输出。\\n字段介绍:输出结果应以数字化的清单形式展示，每条用药建议前标明数字编号，如‘1.’, ‘2.’, ‘3.’，确保信息条理清晰。\\n撰写建议:请提醒患者出院后的注意事项；根据患者的手术过程提醒患者对伤口与拆线的注意事项，与部分手术可能造成的术后情况；描述患者的出院带药。\"\n",
    "response,history= model.chat(tokenizer,test_input, history=[] ,temperature=0.01)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有，病史如下：\n",
      "1. 癫痫病史：曾服用苯妥英钠6年治疗，后病情稳定，未再复发，已停药30余年。\n",
      "2. 脑血管疾病史：有。\n",
      "3. 房颤史：有。\n",
      "4. 高血压病史：有。\n",
      "5. 服用蒙诺0.5片#qd、施慧达1#qd、特TM员工名称TM1#qd、螺内酯1#qd、欣康1#qd、芪苈强心3#tid治疗史：有。\n",
      "6. 口服拜瑞妥史：有。\n",
      "7. 停药6天：有。\n",
      "8. 没有糖尿病、COPD等慢性疾病史：有。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def input_all(ICL, promote1, promote2, question):\n",
    "    return \"{}\\n{}\\n{}\\n\\n患者情况:\\n{}\\n\\n病史总结:\".format(ICL, promote1, promote2, question)\n",
    "\n",
    "text1 = '''疾病史: 高血压病病史15年，血压最高为不详（患者已忘记，无法描述），口服“替米沙坦胶囊80mg qm，苯磺酸左旋氨氯地平片1片 qm”治疗，平日血压控制在130/70mmHg左右。1997年起血小板减少症，自1997年起至今服用强的松1#qd，2019.01.04日复查血常规示血小板20×10^9/L。自述早搏5年，2018年4月住院期间行动态心电图示:房性早搏321次，其中短阵房速5阵；多源室性早搏71次；完全性右束支传导阻滞；ST发作性改变。患者自述偶有心慌感，心慌时自服保心丸后可缓解，现口服稳心颗粒1包 qd治疗。否认糖尿病、冠心病、COPD等慢性疾病史。 传染病史: 否认 传染性疾病史。'''\n",
    "answer1 = '''疾病：高血压,血小板减少症,早搏,心慌'''\n",
    "text2 = '''疾病史: 否认高血压、糖尿病、冠心病、COPD等慢性疾病史。 传染病史: 承认 传染性疾病史，乙肝大三阳20余年，目前服用恩替卡韦1'''\n",
    "answer2 = '''疾病：乙肝'''\n",
    "text3 = '''疾病史: 否认高血压、糖尿病、冠心病、COPD等慢性疾病史 传染病史: 承认或否认 传染性疾病史，疾病名称。'''\n",
    "answer3 = '''疾病：无'''\n",
    "\n",
    "# ICL = compose_zs_prompt_1(text1, answer1) + '\\n' + compose_zs_prompt_1(text2, answer2) + '\\n' + compose_zs_prompt_1(text3, answer3)\n",
    "\n",
    "test_input1=\"疾病史: 承认高血压、糖尿病、冠心病、COPD史。患者没有贫血史。 \"\n",
    "test_input=\"疾病史: 癫痫病史，曾服用苯妥英钠6年治疗，后病情稳定，未再复发，已停药30余年。脑血管疾病、房颤、高血压病史，服用蒙诺0.5片#qd、施慧达1#qd、特TM员工名称TM1#qd、螺内酯1#qd、欣康1#qd、芪苈强心3#tid治疗，口服拜瑞妥，已停药6天。否认糖尿病、COPD等慢性疾病史。\"\n",
    "# test_input = \"一般健康状况: 身体健康 疾病史: 否认高血压、糖尿病、冠心病、COPD等慢性疾病史。患者有贫血史。 传染病史: 否认 传染性疾病史。 预防接种史: 按计划免疫接种。 手术外伤史: 承认 手术史，1993年行剖腹产，否认外伤史。 输血史: 否认输血史 食物过敏史: 否认食物过敏史 药物过敏史: 否认药物过敏史\"\n",
    "test_input=test_input.replace(\"否认\",\"没有\")\n",
    "promote1 = '''疾病列表:[\"乙肝\",\"心肌炎\",\"桥本甲状腺炎\",\"高血压\",\"甲状腺结节\",\"心绞痛\",\"早搏\",\"糖尿病\",\"过敏性支气管炎\",\"肾盂肾炎\",\"子宫肌瘤\",\"肾结石\",\"贫血\",\"垂体微腺瘤\",\"鼻炎\",\"湿疹\",\"甲亢\",\"脑梗\",\"心肌缺血\",\"白内障\",\"鼻窦炎\",\"腰椎间盘突出\",\"胸腺瘤\"]''' \n",
    "promote2 = '''你是一位专业医生，根据患者情况，判断患者是否存在疾病列表中的疾病,存在就输出疾病列表中的疾病，无匹配项就不输出疾病，注意否认高血压、糖尿病、冠心病、COPD等慢性疾病史不应该输出疾病。'''\n",
    "\n",
    "def input_all(ICL, promote1, promote2, question):\n",
    "    return \"{}\\n{}\\n{}\\n\\n患者情况:\\n{}\\n\\n病史总结:\".format(ICL, promote1, promote2, question)\n",
    "\n",
    "# response, history = model.chat(tokenizer, input_all(ICL, promote1, promote2, value), history=[], temperature=0.2)\n",
    "\n",
    "\n",
    "\n",
    "flag2,history= model.chat(tokenizer,\"你是一位专业医生，请根据下面的患者的病史情况描述，判断患者是否有病史，有病史就直接输出‘有’，并输出每个病史，每个病史单独输出，不要输出其他内容。\\n\"+test_input, history=[] ,temperature=0.01)\n",
    "print(flag2)\n",
    "\n",
    "# response,history= model.chat(tokenizer,\"你是一位专业医生，请根据下面的患者的病史情况描述，输出每个病史需要随访的对应的科室，随访的科室是唯一且最恰当的科室，每个病史和对应科室单独输出，输出格式为【病史：科室】，不要输出其他内容。\\n\"+flag2, history=[] ,temperature=0.01)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m result1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m1.患者窦性心动过缓，I°房室传导阻滞，建议于心血管内科随访。患者两肺纹理略多，左下肺小结节影，主动脉迂曲钙化，建议于呼吸科随访。\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m2.10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案。\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m2.术后胸带加压包扎切口5天；之后可佩戴文胸；保持伤口清洁干燥，2周内避免洗澡；术后10天内每3天来院换药一次，换药门诊时间：每周一～周五9:00-11:00 在门诊大楼3楼乳腺中心。\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m3.保持伤口清洁干燥，如有发热，切口局部红肿、疼痛、化脓等不适，及时来院就诊。\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      7\u001b[0m conclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m请你帮我重新给每个句子编号，编号从1开始，不要改写文本，直接输出编号整理好的文本\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m需要编号的文本：\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m conclude_suggestion,history\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconclude\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mresult1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(conclude_suggestion)\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/0229_ck36000_sft_stage4_lora_03-27-09-27-27_export_model/modeling_chatglm.py:1038\u001b[0m, in \u001b[0;36mChatGLMForConditionalGeneration.chat\u001b[0;34m(self, tokenizer, query, history, role, max_length, num_beams, do_sample, top_p, temperature, logits_processor, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1036\u001b[0m eos_token_id \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39meos_token_id, tokenizer\u001b[38;5;241m.\u001b[39mget_command(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|user|>\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1037\u001b[0m                 tokenizer\u001b[38;5;241m.\u001b[39mget_command(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|observation|>\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m-> 1038\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]):\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1040\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs)\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py:1622\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1615\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1616\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1617\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1618\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1619\u001b[0m     )\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1622\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1639\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1640\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1646\u001b[0m     )\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/transformers/generation/utils.py:2791\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2788\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2790\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2791\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2794\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2799\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/0229_ck36000_sft_stage4_lora_03-27-09-27-27_export_model/modeling_chatglm.py:937\u001b[0m, in \u001b[0;36mChatGLMForConditionalGeneration.forward\u001b[0;34m(self, input_ids, position_ids, attention_mask, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, return_last_logit)\u001b[0m\n\u001b[1;32m    934\u001b[0m use_cache \u001b[38;5;241m=\u001b[39m use_cache \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[1;32m    935\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 937\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_last_logit:\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/0229_ck36000_sft_stage4_lora_03-27-09-27-27_export_model/modeling_chatglm.py:830\u001b[0m, in \u001b[0;36mChatGLMModel.forward\u001b[0;34m(self, input_ids, position_ids, attention_mask, full_attention_mask, past_key_values, inputs_embeds, use_cache, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    827\u001b[0m rotary_pos_emb \u001b[38;5;241m=\u001b[39m rotary_pos_emb\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Run encoder.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m hidden_states, presents, all_hidden_states, all_self_attentions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_caches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m [hidden_states, presents, all_hidden_states, all_self_attentions] \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/0229_ck36000_sft_stage4_lora_03-27-09-27-27_export_model/modeling_chatglm.py:640\u001b[0m, in \u001b[0;36mGLMTransformer.forward\u001b[0;34m(self, hidden_states, attention_mask, rotary_pos_emb, kv_caches, use_cache, output_hidden_states)\u001b[0m\n\u001b[1;32m    631\u001b[0m     layer_ret \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    632\u001b[0m         layer,\n\u001b[1;32m    633\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m         use_cache\n\u001b[1;32m    638\u001b[0m     )\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 640\u001b[0m     layer_ret \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_caches\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m hidden_states, kv_cache \u001b[38;5;241m=\u001b[39m layer_ret\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/0229_ck36000_sft_stage4_lora_03-27-09-27-27_export_model/modeling_chatglm.py:544\u001b[0m, in \u001b[0;36mGLMBlock.forward\u001b[0;34m(self, hidden_states, attention_mask, rotary_pos_emb, kv_cache, use_cache)\u001b[0m\n\u001b[1;32m    542\u001b[0m layernorm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# Self attention.\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m attention_output, kv_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayernorm_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# Residual connection.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_residual_connection_post_layernorm:\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/HL_user01/conda/envs/llama_factory/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/0229_ck36000_sft_stage4_lora_03-27-09-27-27_export_model/modeling_chatglm.py:408\u001b[0m, in \u001b[0;36mSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, rotary_pos_emb, kv_cache, use_cache)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# apply relative positional encoding (rotary embedding)\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rotary_pos_emb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     query_layer \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(key_layer, rotary_pos_emb)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# adjust key and value for inference\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result1='''\n",
    "1.患者窦性心动过缓，I°房室传导阻滞，建议于心血管内科随访。患者两肺纹理略多，左下肺小结节影，主动脉迂曲钙化，建议于呼吸科随访。\n",
    "2.10个工作日后来院询问石蜡病理报告，并带至主诊医师门诊就诊，拟定进一步诊疗或随访方案。\n",
    "2.术后胸带加压包扎切口5天；之后可佩戴文胸；保持伤口清洁干燥，2周内避免洗澡；术后10天内每3天来院换药一次，换药门诊时间：每周一～周五9:00-11:00 在门诊大楼3楼乳腺中心。\n",
    "3.保持伤口清洁干燥，如有发热，切口局部红肿、疼痛、化脓等不适，及时来院就诊。\n",
    "'''\n",
    "conclude=\"请你帮我重新给每个句子编号，编号从1开始，不要改写文本，直接输出编号整理好的文本\\n需要编号的文本：\"\n",
    "\n",
    "conclude_suggestion,history= model.chat(tokenizer,conclude+result1, history=[] ,temperature=0.01)\n",
    "print(conclude_suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "患者入院后完善相关检查,并于2019-03-18全麻下行左乳肿物麦默通旋切术,术顺安返,术后予以补液支持治疗。现患者一般情况可,伤口愈合I/甲,经上级医师查房同意后,予以今日出院。2019-03-18石蜡病理报告未出。术后病理报告示:乳腺良性肿瘤(左乳,待石蜡)。术后石蜡病理报告未出。目前患者一般情况可,伤口愈合I/甲,经上级医师查房同意后,予以出院。\n"
     ]
    }
   ],
   "source": [
    "text='''\n",
    "患者入院后完善相关检查,并于2019-03-18全麻下行左乳肿物麦默通旋切术,术顺安返,术后予以补液支持治疗。现患者一般情况\n",
    "可,伤口愈合I/甲,经上级医师查房同意后,予以今日出院。2019-03-18石蜡病理报告未出。术后病理报告示:乳腺良性肿瘤\n",
    "(左乳,待石蜡)。术后石蜡病理报告未出。目前患者一般情况可,伤口愈合I/甲,经上级医师查房同意后,予以出院。\n",
    "'''\n",
    "conclude1,conclude2,conclude3,conclude4,conclude5='综合分析患者的医疗记录，包括手术、化疗、报告和当前情况等，以一段文本总结患者住院期间的整体治疗进展。','从提供的医疗信息中，详细梳理并总结患者在住院期间接受的所有治疗措施，包括手术、化疗、报告及当前情况等。','分析患者的住院病历，提取并概述其在住院期间经历的治疗过程，如手术、化疗、报告和当前情况等。','处理并总结患者在住院期间的病程信息，关注手术、化疗、报告以及和当前情况等关键治疗环节。','对患者的住院病程数据进行分析，集中呈现其在医院期间接受的主要治疗方式，包括手术、化疗、报告及当前情况等信息。'\n",
    "conclude=\"请帮我删除下面这段文本中重复的内容和句子，然后直接输出删除过的文本，不要输出其他内容\\n文本:\\n\"\n",
    "\n",
    "conclusion,history= model.chat(tokenizer,conclude+text, history=[] ,temperature=0.01)\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
